{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Semantic Segmentation Demo\n",
    "\n",
    "This notebook demonstrates the semantic segmentation capabilities of our project. We support multiple models:\n",
    "1. SegFormer-B0 (from Hugging Face)\n",
    "2. DeepLabV3+ (with Edge TPU optimization)\n",
    "3. Mosaic (with Cityscapes classes)\n",
    "\n",
    "Each model can segment images into different semantic classes like roads, buildings, people, cars, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the project root to Python path\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath('.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "from eah_segmentation.inference import run_inference_on_image\n",
    "from eah_segmentation.visualization import colorize_mask\n",
    "\n",
    "# Print TensorFlow version and GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display results\n",
    "def display_results(image, prediction, title=\"Segmentation Results\"):\n",
    "    \"\"\"Display the original image, segmentation mask, and overlay.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Segmentation mask\n",
    "    plt.subplot(132)\n",
    "    colored_mask = colorize_mask(prediction)\n",
    "    plt.imshow(colored_mask)\n",
    "    plt.title(\"Segmentation Mask\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    plt.subplot(133)\n",
    "    overlay = cv2.addWeighted(image, 0.7, colored_mask, 0.3, 0)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(\"Overlay\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess an image\n",
    "def load_image(image_path, target_size=(512, 512)):\n",
    "    \"\"\"Load and preprocess an image for segmentation.\"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image at {image_path}\")\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize image\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "def load_model(model_name):\n",
    "    \"\"\"Load a segmentation model.\"\"\"\n",
    "    model_dir = os.path.join('models', model_name)\n",
    "    if not os.path.exists(model_dir):\n",
    "        raise ValueError(f\"Model directory not found: {model_dir}\")\n",
    "    \n",
    "    model = tf.saved_model.load(model_dir)\n",
    "    print(f\"Successfully loaded {model_name} model\")\n",
    "    return model\n",
    "\n",
    "# Available models\n",
    "MODELS = {\n",
    "    'segformer_b0': {\n",
    "        'input_size': (512, 512),\n",
    "        'description': 'Lightweight SegFormer model for general scene segmentation'\n",
    "    },\n",
    "    'deeplabv3plus_edgetpu': {\n",
    "        'input_size': (512, 512),\n",
    "        'description': 'Edge TPU optimized DeepLabV3+ for efficient inference'\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Running Inference\n",
    "\n",
    "Now let's try running inference with our models. First, we'll need to:\n",
    "1. Load a test image\n",
    "2. Load the models\n",
    "3. Run inference and visualize results\n",
    "\n",
    "Let's start with loading a test image from the data directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a test image\n",
    "# You can replace this with any image path\n",
    "image_path = os.path.join('data', 'test_image.jpg')  # Update this path\n",
    "try:\n",
    "    image = load_image(image_path)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Test Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading image: {str(e)}\")\n",
    "    print(\"Please make sure to place a test image in the data directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference with each model\n",
    "for model_name, model_info in MODELS.items():\n",
    "    print(f\"\\nRunning inference with {model_name}...\")\n",
    "    try:\n",
    "        # Load model\n",
    "        model = load_model(model_name)\n",
    "        \n",
    "        # Run inference\n",
    "        predictions = run_inference_on_image(model, image, model_name)\n",
    "        \n",
    "        # Display results\n",
    "        display_results(image, predictions, f\"Results from {model_name}\")\n",
    "        \n",
    "        # Print unique classes found\n",
    "        unique_classes = np.unique(predictions)\n",
    "        print(f\"\\nDetected classes in {model_name}:\")\n",
    "        for cls in unique_classes:\n",
    "            num_pixels = np.sum(predictions == cls)\n",
    "            percentage = (num_pixels / predictions.size) * 100\n",
    "            print(f\"Class {cls}: {num_pixels} pixels ({percentage:.1f}%)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error running {model_name}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Presentation Demo\n",
    "\n",
    "This notebook demonstrates the semantic segmentation capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
